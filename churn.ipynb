{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# import sklearn Column Transformer and Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "# import sklearn preprocessing classes\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# import Simple imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def to_snake_case(name):\n",
    "    name = name.replace(' ', '_')\n",
    "    name = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', name)\n",
    "    name = re.sub('__([A-Z])', r'_\\1', name)\n",
    "    name = re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', name)\n",
    "    return name.lower().strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>married</th>\n",
       "      <th>number_of_dependents</th>\n",
       "      <th>city</th>\n",
       "      <th>zip_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>number_of_referrals</th>\n",
       "      <th>...</th>\n",
       "      <th>payment_method</th>\n",
       "      <th>monthly_charge</th>\n",
       "      <th>total_charges</th>\n",
       "      <th>total_refunds</th>\n",
       "      <th>total_extra_data_charges</th>\n",
       "      <th>total_long_distance_charges</th>\n",
       "      <th>total_revenue</th>\n",
       "      <th>customer_status</th>\n",
       "      <th>churn_category</th>\n",
       "      <th>churn_reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002-ORFBO</td>\n",
       "      <td>Female</td>\n",
       "      <td>37</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Frazier Park</td>\n",
       "      <td>93225</td>\n",
       "      <td>34.827662</td>\n",
       "      <td>-118.999073</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>65.6</td>\n",
       "      <td>593.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>381.51</td>\n",
       "      <td>974.81</td>\n",
       "      <td>Stayed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0003-MKNFE</td>\n",
       "      <td>Male</td>\n",
       "      <td>46</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Glendale</td>\n",
       "      <td>91206</td>\n",
       "      <td>34.162515</td>\n",
       "      <td>-118.203869</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>542.40</td>\n",
       "      <td>38.33</td>\n",
       "      <td>10</td>\n",
       "      <td>96.21</td>\n",
       "      <td>610.28</td>\n",
       "      <td>Stayed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0004-TLHLJ</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Costa Mesa</td>\n",
       "      <td>92627</td>\n",
       "      <td>33.645672</td>\n",
       "      <td>-117.922613</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Bank Withdrawal</td>\n",
       "      <td>73.9</td>\n",
       "      <td>280.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>134.60</td>\n",
       "      <td>415.45</td>\n",
       "      <td>Churned</td>\n",
       "      <td>Competitor</td>\n",
       "      <td>Competitor had better devices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0011-IGKFF</td>\n",
       "      <td>Male</td>\n",
       "      <td>78</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Martinez</td>\n",
       "      <td>94553</td>\n",
       "      <td>38.014457</td>\n",
       "      <td>-122.115432</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Bank Withdrawal</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1237.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>361.66</td>\n",
       "      <td>1599.51</td>\n",
       "      <td>Churned</td>\n",
       "      <td>Dissatisfaction</td>\n",
       "      <td>Product dissatisfaction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0013-EXCHZ</td>\n",
       "      <td>Female</td>\n",
       "      <td>75</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Camarillo</td>\n",
       "      <td>93010</td>\n",
       "      <td>34.227846</td>\n",
       "      <td>-119.079903</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>83.9</td>\n",
       "      <td>267.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>22.14</td>\n",
       "      <td>289.54</td>\n",
       "      <td>Churned</td>\n",
       "      <td>Dissatisfaction</td>\n",
       "      <td>Network reliability</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id  gender  age married  number_of_dependents          city  \\\n",
       "0  0002-ORFBO  Female   37     Yes                     0  Frazier Park   \n",
       "1  0003-MKNFE    Male   46      No                     0      Glendale   \n",
       "2  0004-TLHLJ    Male   50      No                     0    Costa Mesa   \n",
       "3  0011-IGKFF    Male   78     Yes                     0      Martinez   \n",
       "4  0013-EXCHZ  Female   75     Yes                     0     Camarillo   \n",
       "\n",
       "   zip_code   latitude   longitude  number_of_referrals  ...   payment_method  \\\n",
       "0     93225  34.827662 -118.999073                    2  ...      Credit Card   \n",
       "1     91206  34.162515 -118.203869                    0  ...      Credit Card   \n",
       "2     92627  33.645672 -117.922613                    0  ...  Bank Withdrawal   \n",
       "3     94553  38.014457 -122.115432                    1  ...  Bank Withdrawal   \n",
       "4     93010  34.227846 -119.079903                    3  ...      Credit Card   \n",
       "\n",
       "  monthly_charge total_charges  total_refunds total_extra_data_charges  \\\n",
       "0           65.6        593.30           0.00                        0   \n",
       "1           -4.0        542.40          38.33                       10   \n",
       "2           73.9        280.85           0.00                        0   \n",
       "3           98.0       1237.85           0.00                        0   \n",
       "4           83.9        267.40           0.00                        0   \n",
       "\n",
       "  total_long_distance_charges total_revenue  customer_status   churn_category  \\\n",
       "0                      381.51        974.81           Stayed              NaN   \n",
       "1                       96.21        610.28           Stayed              NaN   \n",
       "2                      134.60        415.45          Churned       Competitor   \n",
       "3                      361.66       1599.51          Churned  Dissatisfaction   \n",
       "4                       22.14        289.54          Churned  Dissatisfaction   \n",
       "\n",
       "                    churn_reason  \n",
       "0                            NaN  \n",
       "1                            NaN  \n",
       "2  Competitor had better devices  \n",
       "3        Product dissatisfaction  \n",
       "4            Network reliability  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"telecom_customer_churn.csv\")\n",
    "df = df.rename(columns=dict(zip(df.columns, list(map(to_snake_case, df.columns)))))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_X = train.drop(\"y\", axis=1)\n",
    "\n",
    "categorical_columns = train_x.select_dtypes(include='object').columns\n",
    "numerical_columns = train_x.select_dtypes(include='number').columns\n",
    "# Create the transformer\n",
    "transformer = ColumnTransformer([\n",
    "    ('num_imputer', SimpleImputer(strategy='median'), numerical_columns),\n",
    "    ('cat_imputer', SimpleImputer(strategy='most_frequent'), categorical_columns),\n",
    "    ('scaler', StandardScaler(), numerical_columns),\n",
    "    ('encoder', OneHotEncoder(), categorical_columns)\n",
    "])\n",
    "ohe = OneHotEncoder()\n",
    "transformer.fit_transform(train[[\"customer_id\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '1686-STUHN'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[39mreturn\u001b[39;00m pipeline\n\u001b[1;32m     39\u001b[0m p \u001b[39m=\u001b[39m build_sklearn_pipeline(train, y)\n\u001b[0;32m---> 40\u001b[0m p\u001b[39m.\u001b[39;49mfit(train\u001b[39m.\u001b[39;49mdrop(y, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m), train[y])\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/End-to-end-project---Customer-churn-PLUo0CZ0/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/End-to-end-project---Customer-churn-PLUo0CZ0/lib/python3.11/site-packages/sklearn/pipeline.py:416\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit the model.\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \n\u001b[1;32m    392\u001b[0m \u001b[39mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[39m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[1;32m    414\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    415\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[0;32m--> 416\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps)\n\u001b[1;32m    417\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n\u001b[1;32m    418\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/End-to-end-project---Customer-churn-PLUo0CZ0/lib/python3.11/site-packages/sklearn/pipeline.py:370\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[1;32m    368\u001b[0m     cloned_transformer \u001b[39m=\u001b[39m clone(transformer)\n\u001b[1;32m    369\u001b[0m \u001b[39m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 370\u001b[0m X, fitted_transformer \u001b[39m=\u001b[39m fit_transform_one_cached(\n\u001b[1;32m    371\u001b[0m     cloned_transformer,\n\u001b[1;32m    372\u001b[0m     X,\n\u001b[1;32m    373\u001b[0m     y,\n\u001b[1;32m    374\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    375\u001b[0m     message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mPipeline\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    376\u001b[0m     message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(step_idx),\n\u001b[1;32m    377\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps[name],\n\u001b[1;32m    378\u001b[0m )\n\u001b[1;32m    379\u001b[0m \u001b[39m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \u001b[39m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    381\u001b[0m \u001b[39m# from the cache.\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[step_idx] \u001b[39m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/End-to-end-project---Customer-churn-PLUo0CZ0/lib/python3.11/site-packages/joblib/memory.py:353\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 353\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunc(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/End-to-end-project---Customer-churn-PLUo0CZ0/lib/python3.11/site-packages/sklearn/pipeline.py:950\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m    949\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(transformer, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 950\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49mfit_transform(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    951\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    952\u001b[0m         res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/End-to-end-project---Customer-churn-PLUo0CZ0/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/End-to-end-project---Customer-churn-PLUo0CZ0/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/End-to-end-project---Customer-churn-PLUo0CZ0/lib/python3.11/site-packages/sklearn/decomposition/_pca.py:460\u001b[0m, in \u001b[0;36mPCA.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    438\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit_transform\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    439\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Fit the model with X and apply the dimensionality reduction on X.\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \n\u001b[1;32m    441\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[39m    C-ordered array, use 'np.ascontiguousarray'.\u001b[39;00m\n\u001b[1;32m    459\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 460\u001b[0m     U, S, Vt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X)\n\u001b[1;32m    461\u001b[0m     U \u001b[39m=\u001b[39m U[:, : \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components_]\n\u001b[1;32m    463\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwhiten:\n\u001b[1;32m    464\u001b[0m         \u001b[39m# X_new = X * V / S * sqrt(n_samples) = U * sqrt(n_samples)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/End-to-end-project---Customer-churn-PLUo0CZ0/lib/python3.11/site-packages/sklearn/decomposition/_pca.py:483\u001b[0m, in \u001b[0;36mPCA._fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m issparse(X):\n\u001b[1;32m    478\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    479\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPCA does not support sparse input. See \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    480\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTruncatedSVD for a possible alternative.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    481\u001b[0m     )\n\u001b[0;32m--> 483\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    484\u001b[0m     X, dtype\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mfloat64, np\u001b[39m.\u001b[39;49mfloat32], ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy\n\u001b[1;32m    485\u001b[0m )\n\u001b[1;32m    487\u001b[0m \u001b[39m# Handle n_components==None\u001b[39;00m\n\u001b[1;32m    488\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_components \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/End-to-end-project---Customer-churn-PLUo0CZ0/lib/python3.11/site-packages/sklearn/base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    602\u001b[0m         out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    603\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 604\u001b[0m     out \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    605\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    606\u001b[0m     out \u001b[39m=\u001b[39m _check_y(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/End-to-end-project---Customer-churn-PLUo0CZ0/lib/python3.11/site-packages/sklearn/utils/validation.py:917\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    915\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    916\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 917\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[1;32m    918\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[1;32m    919\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    920\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    921\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/End-to-end-project---Customer-churn-PLUo0CZ0/lib/python3.11/site-packages/sklearn/utils/_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    378\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39marray(array, order\u001b[39m=\u001b[39morder, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    379\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 380\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39masarray(array, order\u001b[39m=\u001b[39morder, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    382\u001b[0m \u001b[39m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '1686-STUHN'"
     ]
    }
   ],
   "source": [
    "y = \"customer_status\"\n",
    "\n",
    "train, test = train_test_split(\n",
    "    df, test_size=0.2, random_state=0, stratify=df[y])\n",
    "\n",
    "assert df[y].isna().any() == False\n",
    "\n",
    "\n",
    "def build_column_transformer_for_df(train_x: pd.DataFrame) -> ColumnTransformer:\n",
    "    \"\"\"Builds a column transformer for a pandas dataframe.\"\"\"\n",
    "    # Get the categorical and numerical columns\n",
    "    categorical_columns = train_x.select_dtypes(include='object').columns\n",
    "    numerical_columns = train_x.select_dtypes(include='number').columns\n",
    "    # Create the transformer\n",
    "    transformer = ColumnTransformer([\n",
    "        ('num_imputer', SimpleImputer(strategy='median'), numerical_columns),\n",
    "        ('cat_imputer', SimpleImputer(strategy='most_frequent'), categorical_columns),\n",
    "        ('scaler', StandardScaler(), numerical_columns),\n",
    "        ('encoder', OneHotEncoder(sparse_output=False, categories='auto'), categorical_columns)\n",
    "    ], remainder='passthrough')\n",
    "    return transformer\n",
    "\n",
    "\n",
    "def build_sklearn_pipeline(df: pd.DataFrame, y_name:str) -> Pipeline:\n",
    "    \"\"\"Builds a sklearn pipeline for churn prediction.\"\"\"\n",
    "    # Define the steps\n",
    "\n",
    "    column_transformer = build_column_transformer_for_df(df.drop(y_name, axis=1))\n",
    "\n",
    "    steps = [\n",
    "        ('column_transformer', column_transformer),\n",
    "        ('pca', PCA()),\n",
    "        ('logistic', LogisticRegression())\n",
    "    ]\n",
    "    # Create the pipeline\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    return pipeline\n",
    "\n",
    "p = build_sklearn_pipeline(train, y)\n",
    "p.fit(train.drop(y, axis=1), train[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = \"customer_status\"\n",
    "\n",
    "train, test = train_test_split(\n",
    "    df, test_size=0.2, random_state=0, stratify=df[y])\n",
    "\n",
    "assert df[y].isna().any() == False\n",
    "\n",
    "\n",
    "def build_column_transformer_for_df(train_x: pd.DataFrame) -> ColumnTransformer:\n",
    "    \"\"\"Builds a column transformer for a pandas dataframe.\"\"\"\n",
    "    # Get the categorical and numerical columns\n",
    "    categorical_columns = train_x.select_dtypes(include='object').columns\n",
    "    numerical_columns = train_x.select_dtypes(include='number').columns\n",
    "    # Create the transformer\n",
    "    transformer = ColumnTransformer([\n",
    "        ('num_imputer', SimpleImputer(strategy='median'), numerical_columns),\n",
    "        ('cat_imputer', SimpleImputer(strategy='most_frequent'), categorical_columns),\n",
    "        ('scaler', StandardScaler(), numerical_columns),\n",
    "        ('encoder', OneHotEncoder(sparse=False, categories='auto'), categorical_columns)\n",
    "    ], remainder='passthrough')\n",
    "    return transformer\n",
    "\n",
    "\n",
    "def build_sklearn_pipeline(df: pd.DataFrame, y_name:str) -> Pipeline:\n",
    "    \"\"\"Builds a sklearn pipeline for churn prediction.\"\"\"\n",
    "    # Define the steps\n",
    "\n",
    "    column_transformer = build_column_transformer_for_df(df.drop(y_name, axis=1))\n",
    "\n",
    "    steps = [\n",
    "        ('column_transformer', column_transformer),\n",
    "        ('label_encoder', LabelEncoder()),\n",
    "        ('pca', PCA()),\n",
    "        ('logistic', LogisticRegression())\n",
    "    ]\n",
    "    # Create the pipeline\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    return pipeline\n",
    "\n",
    "\n",
    "def sklearn_gridsearch_using_pipeline(train: pd.DataFrame, y_name:str, n_folds: int = 5) -> GridSearchCV:\n",
    "    \"\"\"Performs a grid search using a sklearn pipeline.\"\"\"\n",
    "    # Get the pipeline\n",
    "    pipeline = build_sklearn_pipeline(train, y_name=y_name)\n",
    "\n",
    "    # define stratiefied shuffle split:\n",
    "    sss = StratifiedShuffleSplit(\n",
    "        n_splits=n_folds, test_size=0.2, random_state=0)\n",
    "\n",
    "    # Define the hyperparameter grid\n",
    "    param_grid = {\n",
    "        'pca__n_components': [2, 5, 10, 12, 15, 20, 25],\n",
    "        'logistic__penalty': ['l1', 'l2'],\n",
    "        'logistic__C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "    }\n",
    "\n",
    "    # Perform the grid search\n",
    "    grid = GridSearchCV(pipeline, param_grid, cv=sss, n_jobs=-1, scoring=\"roc_auc\", verbose=5)\n",
    "    grid.fit(train.drop(y, axis=1), train[y])\n",
    "    # Print the results\n",
    "    print('Best score:', grid.best_score_)\n",
    "    print('Best parameters:', grid.best_params_)\n",
    "\n",
    "    return grid\n",
    "\n",
    "grid = sklearn_gridsearch_using_pipeline(train, y_name=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "clf = grid.best_estimator_[\"logistic\"]\n",
    "\n",
    "test_predictions = grid.best_estimator_.predict(test.drop(y, axis=1))\n",
    "cm = confusion_matrix(test[y], test_predictions, labels=clf.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=clf.classes_)\n",
    "\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'predicted_labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\stijn\\anaconda3\\envs\\churn-pred\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\stijn\\anaconda3\\envs\\churn-pred\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\stijn\\anaconda3\\envs\\churn-pred\\lib\\site-packages\\pandas\\_libs\\index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'predicted_labels'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39m12\u001b[39m \u001b[39m*\u001b[39m A\n\u001b[0;32m     14\u001b[0m \u001b[39m# Step 3: Apply the function to calculate the cost for each instance and create the instance-dependent cost matrix\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39minstance_cost\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m row: instance_dependent_cost(row[\u001b[39m'\u001b[39;49m\u001b[39mpredicted_labels\u001b[39;49m\u001b[39m'\u001b[39;49m], row[\u001b[39m'\u001b[39;49m\u001b[39mtrue_labels\u001b[39;49m\u001b[39m'\u001b[39;49m], row[\u001b[39m'\u001b[39;49m\u001b[39mA\u001b[39;49m\u001b[39m'\u001b[39;49m]), axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m     17\u001b[0m \u001b[39m# Print the DataFrame with the instance-dependent cost matrix\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39mprint\u001b[39m(df[[\u001b[39m'\u001b[39m\u001b[39mmonthlycharge\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpredicted_labels\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtrue_labels\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minstance_cost\u001b[39m\u001b[39m'\u001b[39m]])\n",
      "File \u001b[1;32mc:\\Users\\stijn\\anaconda3\\envs\\churn-pred\\lib\\site-packages\\pandas\\core\\frame.py:9568\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9557\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9559\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[0;32m   9560\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   9561\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9566\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[0;32m   9567\u001b[0m )\n\u001b[1;32m-> 9568\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\stijn\\anaconda3\\envs\\churn-pred\\lib\\site-packages\\pandas\\core\\apply.py:764\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[0;32m    762\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[1;32m--> 764\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\stijn\\anaconda3\\envs\\churn-pred\\lib\\site-packages\\pandas\\core\\apply.py:891\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 891\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[0;32m    893\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[0;32m    894\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32mc:\\Users\\stijn\\anaconda3\\envs\\churn-pred\\lib\\site-packages\\pandas\\core\\apply.py:907\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    904\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    905\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[0;32m    906\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 907\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[0;32m    908\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    909\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    910\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    911\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[22], line 15\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39m12\u001b[39m \u001b[39m*\u001b[39m A\n\u001b[0;32m     14\u001b[0m \u001b[39m# Step 3: Apply the function to calculate the cost for each instance and create the instance-dependent cost matrix\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39minstance_cost\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m row: instance_dependent_cost(row[\u001b[39m'\u001b[39;49m\u001b[39mpredicted_labels\u001b[39;49m\u001b[39m'\u001b[39;49m], row[\u001b[39m'\u001b[39m\u001b[39mtrue_labels\u001b[39m\u001b[39m'\u001b[39m], row[\u001b[39m'\u001b[39m\u001b[39mA\u001b[39m\u001b[39m'\u001b[39m]), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     17\u001b[0m \u001b[39m# Print the DataFrame with the instance-dependent cost matrix\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[39mprint\u001b[39m(df[[\u001b[39m'\u001b[39m\u001b[39mmonthlycharge\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpredicted_labels\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtrue_labels\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minstance_cost\u001b[39m\u001b[39m'\u001b[39m]])\n",
      "File \u001b[1;32mc:\\Users\\stijn\\anaconda3\\envs\\churn-pred\\lib\\site-packages\\pandas\\core\\series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    978\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[0;32m    980\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m--> 981\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[0;32m    983\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m    984\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m    985\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    986\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\stijn\\anaconda3\\envs\\churn-pred\\lib\\site-packages\\pandas\\core\\series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1086\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[0;32m   1088\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1089\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[0;32m   1090\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[1;32mc:\\Users\\stijn\\anaconda3\\envs\\churn-pred\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'predicted_labels'"
     ]
    }
   ],
   "source": [
    "df['A'] = df['monthlycharge']\n",
    "\n",
    "# Step 2: Define a function to calculate the instance-dependent cost\n",
    "def instance_dependent_cost(predicted_label, true_label, A):\n",
    "    if true_label == 1 and predicted_label == 1:  # True Positive (TP)\n",
    "        return 0\n",
    "    elif true_label == 0 and predicted_label == 1:  # False Positive (FP)\n",
    "        return 2 * A\n",
    "    elif true_label == 0 and predicted_label == 0:  # True Negative (TN)0\n",
    "        return 0\n",
    "    elif true_label == 1 and predicted_label == 0:  # False Negative (FN)\n",
    "        return 12 * A\n",
    "\n",
    "# Step 3: Apply the function to calculate the cost for each instance and create the instance-dependent cost matrix\n",
    "df['instance_cost'] = df.apply(lambda row: instance_dependent_cost(row['predicted_labels'], row['true_labels'], row['A']), axis=1)\n",
    "\n",
    "# Print the DataFrame with the instance-dependent cost matrix\n",
    "print(df[['monthlycharge', 'predicted_labels', 'true_labels', 'instance_cost']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[258], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49marray([[\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m], [\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m], \u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m.\u001b[39;49m])  \u001b[39m# Replace '...' with your actual features\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Example binary target labels\u001b[39;00m\n\u001b[0;32m      4\u001b[0m y_train \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m])  \u001b[39m# Replace with your actual target labels\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (3,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "X_train = np.array([[...], [...], ...])  # Replace '...' with your actual features\n",
    "\n",
    "# Example binary target labels\n",
    "y_train = np.array([0, 1, 1, 0])  # Replace with your actual target labels\n",
    "\n",
    "# Create a list to store instance-dependent predicted probabilities (X values)\n",
    "instance_probs = []\n",
    "\n",
    "# Train a logistic regression model for each instance and get the predicted probabilities\n",
    "for i in range(len(X_train)):\n",
    "    # Select the i-th instance as a single-sample training set\n",
    "    X_single_instance = X_train[i].reshape(1, -1)\n",
    "    y_single_instance = y_train[i]\n",
    "\n",
    "    # Create a logistic regression model\n",
    "    model = LogisticRegression()\n",
    "\n",
    "    # Fit the model to the single-instance data\n",
    "    model.fit(X_single_instance, [y_single_instance])\n",
    "\n",
    "    # Predict the probability for class 1 (positive class)\n",
    "    prob_class_1 = model.predict_proba(X_single_instance)[:, 1]\n",
    "\n",
    "    # Append the predicted probability to the list\n",
    "    instance_probs.append(prob_class_1[0])\n",
    "\n",
    "# Convert the list to a numpy array\n",
    "X_predicted_probs = np.array(instance_probs)\n",
    "\n",
    "# Now, X_predicted_probs contains the instance-dependent predicted probabilities (X values)\n",
    "print(\"Instance-Dependent Predicted Probabilities (X):\", X_predicted_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_cost(hypothesis, y_true):\n",
    "    # Ensure the hypothesis values are clipped to avoid taking the logarithm of zero\n",
    "    epsilon = 1e-15\n",
    "    hypothesis = np.clip(hypothesis, epsilon, 1 - epsilon)\n",
    "\n",
    "    # Calculate the cross-entropy cost\n",
    "    cost = -np.mean(y_true * np.log(hypothesis) + (1 - y_true) * np.log(1 - hypothesis))\n",
    "    return cost\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for axis 0 with size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[257], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m y_true \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m])\n\u001b[1;32m----> 2\u001b[0m instance_costs \u001b[39m=\u001b[39m [cross_entropy_cost(X[i], y_true[i]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(X))]\n",
      "Cell \u001b[1;32mIn[257], line 2\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m y_true \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m])\n\u001b[1;32m----> 2\u001b[0m instance_costs \u001b[39m=\u001b[39m [cross_entropy_cost(X[i], y_true[i]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(X))]\n",
      "\u001b[1;31mIndexError\u001b[0m: index 4 is out of bounds for axis 0 with size 4"
     ]
    }
   ],
   "source": [
    "y_true = np.array([0, 1, 1, 0])\n",
    "instance_costs = [cross_entropy_cost(X[i], y_true[i]) for i in range(len(X))]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "churn-pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
