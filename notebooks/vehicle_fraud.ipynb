{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from typing import List\n",
    "import sys\n",
    "\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from src.common_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fraud_found_p\n",
       "0    94.014267\n",
       "1     5.985733\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample data\n",
    "RAW_DATA_PATH = \"../datasets/fraud/vehicle_fraud.csv\"\n",
    "DATASET_NAME = Path(RAW_DATA_PATH).stem\n",
    "df = pd.read_csv(RAW_DATA_PATH)\n",
    "df = df.rename(columns=dict(zip(df.columns, list(map(to_snake_case, df.columns)))))\n",
    "df.head()\n",
    "print(df.shape[0])\n",
    "df[\"fraud_found_p\"].value_counts()/df.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month                    False\n",
       "week_of_month            False\n",
       "day_of_week              False\n",
       "make                     False\n",
       "accident_area            False\n",
       "day_of_week_claimed      False\n",
       "month_claimed            False\n",
       "week_of_month_claimed    False\n",
       "sex                      False\n",
       "marital_status           False\n",
       "age                      False\n",
       "fault                    False\n",
       "policy_type              False\n",
       "vehicle_category         False\n",
       "vehicle_price            False\n",
       "fraud_found_p            False\n",
       "policy_number            False\n",
       "rep_number               False\n",
       "deductible               False\n",
       "driver_rating            False\n",
       "days_policy_accident     False\n",
       "days_policy_claim        False\n",
       "past_number_of_claims    False\n",
       "age_of_vehicle           False\n",
       "age_of_policy_holder     False\n",
       "police_report_filed      False\n",
       "witness_present          False\n",
       "agent_type               False\n",
       "number_of_suppliments    False\n",
       "address_change_claim     False\n",
       "number_of_cars           False\n",
       "year                     False\n",
       "base_policy              False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make       fraud_found_p\n",
       "Pontiac    0                3624\n",
       "Toyota     0                2935\n",
       "Honda      0                2622\n",
       "Mazda      0                2231\n",
       "Chevrolet  0                1587\n",
       "Ford       0                 417\n",
       "Accura     0                 413\n",
       "VW         0                 275\n",
       "Pontiac    1                 213\n",
       "Toyota     1                 186\n",
       "Honda      1                 179\n",
       "Mazda      1                 123\n",
       "Dodge      0                 107\n",
       "Saab       0                  97\n",
       "Chevrolet  1                  94\n",
       "Mercury    0                  77\n",
       "Accura     1                  59\n",
       "Saturn     0                  52\n",
       "Ford       1                  33\n",
       "Nisson     0                  29\n",
       "BMW        0                  14\n",
       "Saab       1                  11\n",
       "VW         1                   8\n",
       "Jaguar     0                   6\n",
       "Saturn     1                   6\n",
       "Mercury    1                   6\n",
       "Porche     0                   5\n",
       "Mecedes    0                   3\n",
       "Ferrari    0                   2\n",
       "Dodge      1                   2\n",
       "Lexus      0                   1\n",
       "BMW        1                   1\n",
       "Nisson     1                   1\n",
       "Mecedes    1                   1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.value_counts([\"make\", \"fraud_found_p\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accident_area            object\n",
       "address_change_claim     object\n",
       "age                       int64\n",
       "age_of_policy_holder     object\n",
       "age_of_vehicle           object\n",
       "agent_type               object\n",
       "base_policy              object\n",
       "day_of_week              object\n",
       "day_of_week_claimed      object\n",
       "days_policy_accident     object\n",
       "days_policy_claim        object\n",
       "deductible                int64\n",
       "driver_rating             int64\n",
       "fault                    object\n",
       "fraud_found_p             int64\n",
       "make                     object\n",
       "marital_status           object\n",
       "month                    object\n",
       "month_claimed            object\n",
       "number_of_cars           object\n",
       "number_of_suppliments    object\n",
       "past_number_of_claims    object\n",
       "police_report_filed      object\n",
       "policy_number             int64\n",
       "policy_type              object\n",
       "rep_number                int64\n",
       "sex                      object\n",
       "vehicle_category         object\n",
       "vehicle_price            object\n",
       "week_of_month             int64\n",
       "week_of_month_claimed     int64\n",
       "witness_present          object\n",
       "year                      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[sorted(df.columns)].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = \"fraud_found_p\"\n",
    "\n",
    "# some generic cleaning\n",
    "df = df.loc[df.day_of_week_claimed!=0]\n",
    "df = df.loc[df.policy_type!=\"Sport - Liability\"]\n",
    "df[\"vehicle_price\"] = df[\"vehicle_price\"].str.replace(\"less than \", \"\").str.replace(\"more than \", \"\").str.split(\" to\").str[0].astype(int)\n",
    "df[\"past_number_of_claims\"]= df[\"past_number_of_claims\"].str.replace(\"none\", \"0\").str.replace(\"more than \", \"\").str.split(\"\").str[1:3].str.join(\"\").str.strip().astype(int)\n",
    "df[\"days_policy_claim\"] = df[\"days_policy_claim\"].str.replace(\"none\", \"0\").str.replace(\"more than \", \"\").str.split(\"\").str[1:3].str.join(\"\").str.strip().astype(int)\n",
    "df[\"days_policy_accident\"] = df[\"days_policy_accident\"].str.replace(\"none\", \"0\").str.replace(\"more than \", \"\").str.split(\"\").str[1:3].str.join(\"\").str.strip().astype(int)\n",
    "df[\"age_of_vehicle\"] = df[\"age_of_vehicle\"].str.replace(\"new\", \"0\").str.replace(\"more than \", \"\").str.split(\"\").str[1].astype(int)\n",
    "df[\"age_of_policy_holder\"] = df[\"age_of_policy_holder\"].str.replace(\"over \", \"\").str.split(\"\").str[1:3].str.join(\"\").astype(int)\n",
    "df[\"address_change_claim\"] = df[\"address_change_claim\"].str.split(\"\").str[1].str.replace(\"n\", \"0\").str.replace(\"u\", \"0.25\").astype(float)\n",
    "df[\"number_of_suppliments\"] = df[\"number_of_suppliments\"].str.split(\"\").str[1].str.replace(\"n\", \"0\").str.replace(\"m\", \"5\").astype(int)\n",
    "df['number_of_cars'] = df.number_of_cars.str.split(\"\").str[1].str.replace(\"m\", \"8\")\n",
    "df[\"number_of_cars_as_int\"] = df[\"number_of_cars\"].str.split(\"\").str[1].str.replace(\"m\", \"8\").astype(int)\n",
    "COLUMNS_TO_DROP = [\"address_change_claim\", \"number_of_cars\", \"policy_number\"]\n",
    "assert df[y].isna().any() == False\n",
    "# drop single row with Lexus as encoder can't handle cases seen in only train, while encoding test\n",
    "drop_condition = ((df.make.isin([\"Lexus\", \"Ferrari\", \"Mecedes\"])) | (\n",
    "    df.make.isin([\"BMW\", \"Nisson\", \"Mecedes\"]) & (df[y] == 1)))\n",
    "raw_features = df.drop(\n",
    "    COLUMNS_TO_DROP, axis=1).loc[~drop_condition]\n",
    "\n",
    "# ML tuning\n",
    "# add make otherwise there are unknown brands in test set, and encoder can't handle\n",
    "train, test = train_test_split(\n",
    "    raw_features, test_size=0.2, random_state=0, stratify=raw_features[[y]])\n",
    "\n",
    "fit_le = LabelEncoder().fit(train[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0] - raw_features.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_column_transformer_for_df(train_x: pd.DataFrame, text_columns:List[str]) -> ColumnTransformer:\n",
    "#     \"\"\"Builds a column transformer for a pandas dataframe.\"\"\"\n",
    "#     # Get the categorical and numerical columns\n",
    "#     categorical_columns = train_x.select_dtypes(\n",
    "#         include='object').columns.to_list()\n",
    "#     numerical_columns = train_x.select_dtypes(\n",
    "#         include='number').columns.to_list()\n",
    "\n",
    "#     num_prep = Pipeline(steps=[\n",
    "#         ('num_imputer', SimpleImputer(strategy='median')),\n",
    "#         ('scaler', StandardScaler())\n",
    "#     ])\n",
    "\n",
    "#     cat_prep = Pipeline(steps=[\n",
    "#         ('cat_imputer', SimpleImputer(strategy='most_frequent')),\n",
    "#         ('encoder', OneHotEncoder(sparse_output=False))\n",
    "#     ])\n",
    "\n",
    "#     transformer = ColumnTransformer([\n",
    "#         ('text', TfidfVectorizer(), text_columns),\n",
    "#         ('num', num_prep, numerical_columns),\n",
    "#         ('cat', cat_prep, categorical_columns)\n",
    "#     ])\n",
    "\n",
    "#     return transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline = build_sklearn_pipeline(train, y, model_name=\"logistic\", model=LogisticRegression())\n",
    "# pipeline.fit(train.drop(y, axis=1), train[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 576 candidates, totalling 2880 fits\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'logistic__penalty': ['l2'],\n",
    "    'logistic__C': [1, 10, 100, 1000],\n",
    "    'pca__n_components': list(range(6, 32, 8)),\n",
    "    'under__sampling_strategy': [0.1, 0.2, 0.3, 0.5, 0.7, 1],\n",
    "    'over__sampling_strategy': [0.2, 0.3, 0.4, 0.5, 0.7, 1]\n",
    "}\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "MODEL_NAME = 'logistic'\n",
    "\n",
    "# text_columns = [\"address_change_claim\"]\n",
    "\n",
    "# steps = build_column_transformer_for_df(\n",
    "#     train_x=train.drop(y, axis=1))._transformers\n",
    "# steps.insert(0, ('text', TfidfVectorizer(), [text_column]))\n",
    "# preprocessor = ColumnTransformer(steps)\n",
    "\n",
    "# preprocessor = build_column_transformer_for_df(train.drop(y, axis=1), text_columns)\n",
    "# pipeline = build_sklearn_pipeline(\n",
    "#     train, y_col_name=y, model_name=MODEL_NAME, model=model, transformer=preprocessor)\n",
    "grid = sklearn_gridsearch_using_pipeline(train, y_col_name=y, model_name=MODEL_NAME,\n",
    "                                  model=model, fit_le=fit_le, param_grid=param_grid, verbose=1, n_folds=5) #, pipeline=pipeline)\n",
    "best_pipeline_log_reg = grid.best_estimator_\n",
    "best_pipeline_log_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_pipeline(best_pipeline_log_reg, MODEL_NAME, DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_pipeline_log_reg = load_pipeline(model_name=MODEL_NAME, dataset_name=DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found unknown categories ['0'] in column 4 during transform",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m evaluate_model(best_pipeline_log_reg, fit_le\u001b[39m=\u001b[39;49mfit_le, test\u001b[39m=\u001b[39;49mtest, y_col_name\u001b[39m=\u001b[39;49my)\n",
      "File \u001b[0;32m~/projects/End-to-end-project---Customer-churn/notebooks/../src/common_functions.py:131\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(best_pipeline, fit_le, test, y_col_name)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate_model\u001b[39m(best_pipeline: Pipeline, fit_le: LabelEncoder, test: pd\u001b[39m.\u001b[39mDataFrame, y_col_name: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     clf \u001b[39m=\u001b[39m best_pipeline[\u001b[39m\"\u001b[39m\u001b[39mlogistic\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m--> 131\u001b[0m     test_predictions \u001b[39m=\u001b[39m best_pipeline\u001b[39m.\u001b[39;49mpredict(\n\u001b[1;32m    132\u001b[0m         test\u001b[39m.\u001b[39;49mdrop(y_col_name, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m))\n\u001b[1;32m    133\u001b[0m     test_predictions_proba \u001b[39m=\u001b[39m best_pipeline\u001b[39m.\u001b[39mpredict_proba(\n\u001b[1;32m    134\u001b[0m         test\u001b[39m.\u001b[39mdrop(y_col_name, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m    136\u001b[0m     test_y_encoded \u001b[39m=\u001b[39m fit_le\u001b[39m.\u001b[39mtransform(test[y_col_name])\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/End-to-end-project---Customer-churn-PLUo0CZ0/lib/python3.11/site-packages/sklearn/pipeline.py:507\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    505\u001b[0m Xt \u001b[39m=\u001b[39m X\n\u001b[1;32m    506\u001b[0m \u001b[39mfor\u001b[39;00m _, name, transform \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter(with_final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m--> 507\u001b[0m     Xt \u001b[39m=\u001b[39m transform\u001b[39m.\u001b[39;49mtransform(Xt)\n\u001b[1;32m    508\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m][\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mpredict(Xt, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpredict_params)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/End-to-end-project---Customer-churn-PLUo0CZ0/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/End-to-end-project---Customer-churn-PLUo0CZ0/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:816\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    812\u001b[0m     \u001b[39m# ndarray was used for fitting or transforming, thus we only\u001b[39;00m\n\u001b[1;32m    813\u001b[0m     \u001b[39m# check that n_features_in_ is consistent\u001b[39;00m\n\u001b[1;32m    814\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_n_features(X, reset\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 816\u001b[0m Xs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_transform(\n\u001b[1;32m    817\u001b[0m     X,\n\u001b[1;32m    818\u001b[0m     \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    819\u001b[0m     _transform_one,\n\u001b[1;32m    820\u001b[0m     fitted\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    821\u001b[0m     column_as_strings\u001b[39m=\u001b[39;49mfit_dataframe_and_transform_dataframe,\n\u001b[1;32m    822\u001b[0m )\n\u001b[1;32m    823\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_output(Xs)\n\u001b[1;32m    825\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m Xs:\n\u001b[1;32m    826\u001b[0m     \u001b[39m# All transformers are None\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/End-to-end-project---Customer-churn-PLUo0CZ0/lib/python3.11/site-packages/sklearn/compose/_column_transformer.py:670\u001b[0m, in \u001b[0;36mColumnTransformer._fit_transform\u001b[0;34m(self, X, y, func, fitted, column_as_strings)\u001b[0m\n\u001b[1;32m    664\u001b[0m transformers \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[1;32m    665\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter(\n\u001b[1;32m    666\u001b[0m         fitted\u001b[39m=\u001b[39mfitted, replace_strings\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, column_as_strings\u001b[39m=\u001b[39mcolumn_as_strings\n\u001b[1;32m    667\u001b[0m     )\n\u001b[1;32m    668\u001b[0m )\n\u001b[1;32m    669\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 670\u001b[0m     \u001b[39mreturn\u001b[39;00m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs)(\n\u001b[1;32m    671\u001b[0m         delayed(func)(\n\u001b[1;32m    672\u001b[0m             transformer\u001b[39m=\u001b[39;49mclone(trans) \u001b[39mif\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m fitted \u001b[39melse\u001b[39;49;00m trans,\n\u001b[1;32m    673\u001b[0m             X\u001b[39m=\u001b[39;49m_safe_indexing(X, column, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m),\n\u001b[1;32m    674\u001b[0m             y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    675\u001b[0m             weight\u001b[39m=\u001b[39;49mweight,\n\u001b[1;32m    676\u001b[0m             message_clsname\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mColumnTransformer\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    677\u001b[0m             message\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_log_message(name, idx, \u001b[39mlen\u001b[39;49m(transformers)),\n\u001b[1;32m    678\u001b[0m         )\n\u001b[1;32m    679\u001b[0m         \u001b[39mfor\u001b[39;49;00m idx, (name, trans, column, weight) \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(transformers, \u001b[39m1\u001b[39;49m)\n\u001b[1;32m    680\u001b[0m     )\n\u001b[1;32m    681\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    682\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mstr\u001b[39m(e):\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/End-to-end-project---Customer-churn-PLUo0CZ0/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/End-to-end-project---Customer-churn-PLUo0CZ0/lib/python3.11/site-packages/joblib/parallel.py:1855\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1853\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1854\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1855\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[1;32m   1857\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1858\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1859\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1860\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1861\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1862\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/End-to-end-project---Customer-churn-PLUo0CZ0/lib/python3.11/site-packages/joblib/parallel.py:1784\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1782\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1783\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1784\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1785\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1786\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/End-to-end-project---Customer-churn-PLUo0CZ0/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/End-to-end-project---Customer-churn-PLUo0CZ0/lib/python3.11/site-packages/sklearn/pipeline.py:933\u001b[0m, in \u001b[0;36m_transform_one\u001b[0;34m(transformer, X, y, weight, **fit_params)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_transform_one\u001b[39m(transformer, X, y, weight, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params):\n\u001b[0;32m--> 933\u001b[0m     res \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49mtransform(X)\n\u001b[1;32m    934\u001b[0m     \u001b[39m# if we have a weight for this transformer, multiply output\u001b[39;00m\n\u001b[1;32m    935\u001b[0m     \u001b[39mif\u001b[39;00m weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/End-to-end-project---Customer-churn-PLUo0CZ0/lib/python3.11/site-packages/sklearn/pipeline.py:689\u001b[0m, in \u001b[0;36mPipeline.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    687\u001b[0m Xt \u001b[39m=\u001b[39m X\n\u001b[1;32m    688\u001b[0m \u001b[39mfor\u001b[39;00m _, _, transform \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter():\n\u001b[0;32m--> 689\u001b[0m     Xt \u001b[39m=\u001b[39m transform\u001b[39m.\u001b[39;49mtransform(Xt)\n\u001b[1;32m    690\u001b[0m \u001b[39mreturn\u001b[39;00m Xt\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/End-to-end-project---Customer-churn-PLUo0CZ0/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/End-to-end-project---Customer-churn-PLUo0CZ0/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:1016\u001b[0m, in \u001b[0;36mOneHotEncoder.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1011\u001b[0m \u001b[39m# validation of X happens in _check_X called by _transform\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m warn_on_unknown \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdrop \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_unknown \u001b[39min\u001b[39;00m {\n\u001b[1;32m   1013\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1014\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39minfrequent_if_exist\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1015\u001b[0m }\n\u001b[0;32m-> 1016\u001b[0m X_int, X_mask \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transform(\n\u001b[1;32m   1017\u001b[0m     X,\n\u001b[1;32m   1018\u001b[0m     handle_unknown\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle_unknown,\n\u001b[1;32m   1019\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1020\u001b[0m     warn_on_unknown\u001b[39m=\u001b[39;49mwarn_on_unknown,\n\u001b[1;32m   1021\u001b[0m )\n\u001b[1;32m   1023\u001b[0m n_samples, n_features \u001b[39m=\u001b[39m X_int\u001b[39m.\u001b[39mshape\n\u001b[1;32m   1025\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_drop_idx_after_grouping \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/End-to-end-project---Customer-churn-PLUo0CZ0/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:199\u001b[0m, in \u001b[0;36m_BaseEncoder._transform\u001b[0;34m(self, X, handle_unknown, force_all_finite, warn_on_unknown, ignore_category_indices)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mif\u001b[39;00m handle_unknown \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    195\u001b[0m     msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    196\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound unknown categories \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m in column \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    197\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m during transform\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(diff, i)\n\u001b[1;32m    198\u001b[0m     )\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[1;32m    200\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m     \u001b[39mif\u001b[39;00m warn_on_unknown:\n",
      "\u001b[0;31mValueError\u001b[0m: Found unknown categories ['0'] in column 4 during transform"
     ]
    }
   ],
   "source": [
    "evaluate_model(best_pipeline_log_reg, fit_le=fit_le, test=test, y_col_name=y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "End-to-end-project---Customer-churn-PLUo0CZ0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
